{\rtf1\ansi\ansicpg1252\cocoartf2577
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww15500\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Data Scientist Role Play: Profiling and Analyzing the Yelp Dataset Coursera Worksheet\
\
This is a 2-part assignment. In the first part, you are asked a series of questions that will help you profile and understand the data just like a data scientist would. For this first part of the assignment, you will be assessed both on the correctness of your findings, as well as the code you used to arrive at your answer. You will be graded on how easy your code is to read, so remember to use proper formatting and comments where necessary.\
\
In the second part of the assignment, you are asked to come up with your own inferences and analysis of the data for a particular research question you want to answer. You will be required to prepare the dataset for the analysis you choose to do. As with the first part, you will be graded, in part, on how easy your code is to read, so use proper formatting and comments to illustrate and communicate your intent as required.\
\
For both parts of this assignment, use this "worksheet." It provides all the questions you are being asked, and your job will be to transfer your answers and SQL coding where indicated into this worksheet so that your peers can review your work. You should be able to use any Text Editor (Windows Notepad, Apple TextEdit, Notepad ++, Sublime Text, etc.) to copy and paste your answers. If you are going to use Word or some other page layout application, just be careful to make sure your answers and code are lined appropriately.\
In this case, you may want to save as a PDF to ensure your formatting remains intact for you reviewer.\
\
\
\
Part 1: Yelp Dataset Profiling and Understanding\
\
1. Profile the data by finding the total number of records for each of the tables below:\
	\
i. Attribute table = 10,000 records\
ii. Business table = 10,000 records\
iii. Category table = 10,000 records\
iv. Checkin table = 10,000 records\
v. elite_years table = 10,000 records\
vi. friend table = 10,000 records\
vii. hours table = 10,000 records\
viii. photo table = 10,000 records\
ix. review table = 10,000 records\
x. tip table = 10,000 records\
xi. user table = 10,000 records\
	\
\
\
2. Find the total distinct records by either the foreign key or primary key for each table. If two foreign keys are listed in the table, please specify which foreign key.\
\
i. Business = 10,000\
ii. Hours = 1562\
iii. Category = 2643\
iv. Attribute = 1115\
v. Review = 10,000\
vi. Checkin = 493\
vii. Photo = 10,000\
viii. Tip = 537 records and user_id are the foreign keys \
ix. User = 10,000\
x. Friend = 11\
xi. Elite_years = 2780\
\
Note: Primary Keys are denoted in the ER-Diagram with a yellow key icon.	\
\
\
\
3. Are there any columns with null values in the Users table? Indicate "yes," or "no."\
\
	Answer: no\
	\
	\
	SQL code used to arrive at answer:\
\
	select * \
	from user\
	where id is null\
	\
\
	\
4. For each table and column listed below, display the smallest (minimum), largest (maximum), and average (mean) value for the following fields:\
\
	i. Table: Review, Column: Stars\
	\
		min:	1	max:	5	avg:  	3.7082 \
		\
	\
	ii. Table: Business, Column: Stars\
	\
		min:	1.0	max:	5.0	avg:  	3.6549\
		\
	\
	iii. Table: Tip, Column: Likes\
	\
		min:	0	max:	2	avg:  	0.0144\
		\
	\
	iv. Table: Checkin, Column: Count\
	\
		min:	1	max:	53	avg:  	1.9414\
		\
	\
	v. Table: User, Column: Review_count\
	\
		min:	0	max:	2000	avg:	24.2995\
		\
\
\
5. List the cities with the most reviews in descending order:\
\
	SQL code used to arrive at answer:\
	\
	select city, sum(review_count) as mostreviews\
	from business\
	group by city\
	order by mostreviews desc\
\
	\
	Copy and Paste the Result Below:\
	\
+-----------------+-------------+\
| city            | mostreviews |\
+-----------------+-------------+\
| Las Vegas       |       82854 |\
| Phoenix         |       34503 |\
| Toronto         |       24113 |\
| Scottsdale      |       20614 |\
| Charlotte       |       12523 |\
| Henderson       |       10871 |\
| Tempe           |       10504 |\
| Pittsburgh      |        9798 |\
| Montr\'c3\'a9al        |        9448 |\
| Chandler        |        8112 |\
| Mesa            |        6875 |\
| Gilbert         |        6380 |\
| Cleveland       |        5593 |\
| Madison         |        5265 |\
| Glendale        |        4406 |\
| Mississauga     |        3814 |\
| Edinburgh       |        2792 |\
| Peoria          |        2624 |\
| North Las Vegas |        2438 |\
| Markham         |        2352 |\
| Champaign       |        2029 |\
| Stuttgart       |        1849 |\
| Surprise        |        1520 |\
| Lakewood        |        1465 |\
| Goodyear        |        1155 |\
+-----------------+-------------+\
(Output limit exceeded, 25 of 362 total rows shown)\
\
\
	\
6. Find the distribution of star ratings to the business in the following cities:\
\
i. Avon\
\
SQL code used to arrive at answer:\
\
select stars as StarRating, count(review_count) as count\
from business\
where city = "Avon"\
group by StarRating\
\
\
Copy and Paste the Resulting Table Below (2 columns \'c3\'a2\'e2\'82\'ac\'e2\'80\'9c star rating and count):\
\
+------------+-------+\
| StarRating | count |\
+------------+-------+\
|        1.5 |     1 |\
|        2.5 |     2 |\
|        3.5 |     3 |\
|        4.0 |     2 |\
|        4.5 |     1 |\
|        5.0 |     1 |\
+------------+-------+\
\
ii. Beachwood\
\
SQL code used to arrive at answer:\
\
select stars as StarRating, count(review_count) as count\
from business\
where city = "Beachwood"\
group by StarRating\
\
\
Copy and Paste the Resulting Table Below (2 columns \'c3\'a2\'e2\'82\'ac\'e2\'80\'9c star rating and count):\
		\
+------------+-------+\
| StarRating | count |\
+------------+-------+\
|        2.0 |     1 |\
|        2.5 |     1 |\
|        3.0 |     2 |\
|        3.5 |     2 |\
|        4.0 |     1 |\
|        4.5 |     2 |\
|        5.0 |     5 |\
+------------+-------+\
\
7. Find the top 3 users based on their total number of reviews:\
		\
	SQL code used to arrive at answer:\
	\
select name, review_count as counts\
from user\
order by counts desc\
limit 3\
		\
	Copy and Paste the Result Below:\
		\
+--------+--------+\
| name   | counts |\
+--------+--------+\
| Gerald |   2000 |\
| Sara   |   1629 |\
| Yuri   |   1339 |\
+--------+--------+\
\
\
8. Does posing more reviews correlate with more fans?\
\
	Please explain your findings and interpretation of the results:\
	\
select name, count(review_count) as counts, sum(fans) as fan\
from user\
group by name\
order by counts desc\
\
+---------+--------+-----+\
| name    | counts | fan |\
+---------+--------+-----+\
| John    |    102 |  46 |\
| David   |     90 |  25 |\
| Chris   |     74 |  52 |\
| Mike    |     74 | 119 |\
| Michael |     72 |  34 |\
+---------+--------+-----+\
\
select name, count(review_count) as counts, sum(fans) as fan\
from user\
group by name\
order by fans desc\
limit 5	\
\
+---------+--------+-----+\
| name    | counts | fan |\
+---------+--------+-----+\
| Gerald  |      2 | 256 |\
| Lissa   |      2 | 120 |\
| bernice |      1 | 105 |\
| Roanna  |      1 | 104 |\
| .Hon    |      1 | 101 |\
+---------+--------+-----+\
\
Not necessarily. The user with the most fans named Gerald has only 2 reviews. While the user with the most reviews called John has only 46 fans \
\
\
9. Are there more reviews with the word "love" or with the word "hate" in them?\
\
	Answer: Yes, there are 1780 reviews with the word "love" and 232 reviews with the word "hate" \
\
	\
	SQL code used to arrive at answer:\
\
select count(stars) as counwords\
from review\
WHERE text LIKE "%hate%"\
union\
select count(stars)\
from review\
WHERE text LIKE "%love%"\
	\
10. Find the top 10 users with the most fans:\
\
	SQL code used to arrive at answer:\
	\
select name, fans as TotalFans\
from user\
order by fans desc\
limit 10\
\
	Copy and Paste the Result Below:\
\
+-----------+-----------+\
| name      | TotalFans |\
+-----------+-----------+\
| Amy       |       503 |\
| Mimi      |       497 |\
| Harald    |       311 |\
| Gerald    |       253 |\
| Christine |       173 |\
| Lisa      |       159 |\
| Cat       |       133 |\
| William   |       126 |\
| Fran      |       124 |\
| Lissa     |       120 |\
+-----------+-----------+\
\
Part 2: Inferences and Analysis\
\
1. Pick one city and category of your choice and group the businesses in that city or category by their overall star rating. Compare the businesses with 2-3 stars to the businesses with 4-5 stars and answer the following questions. Include your code.\
	\
i. Do the two groups you chose to analyze have a different distribution of hours?\
\
I wasnt able to do it\
\
ii. Do the two groups you chose to analyze have a different number of reviews?\
\
Yes, the 2-3 star group has 403 reviews and the 4-5 star group has 838 reviews:\
\
SQL code:\
\
select city, trim("stars 2-3") as Stars, count(review_count) as NumberReview\
from business\
where city = "Las Vegas" and (stars between 2 and 3) \
union \
select city, trim("stars 4-5") as Stars, count(review_count) as NumberReview\
from business\
where city = "Las Vegas" and (stars between 4 and 5) \
\
+-----------+-----------+--------------+\
| city      | Stars     | NumberReview |\
+-----------+-----------+--------------+\
| Las Vegas | stars 2-3 |          403 |\
| Las Vegas | stars 4-5 |          838 |\
+-----------+-----------+--------------+\
         \
         \
iii. Are you able to infer anything from the location data provided between these two groups? Explain.\
\
It is not possible to infer significant results when analyzing the longitude and latitude of the two groups. \
This is due to the fact that when filtered by the city of "Las Vegas", a close longitude and latitude is set a priori. \
\
SQL code used for analysis:\
\
select city, trim("stars 2-3") as Stars, avg(latitude), avg(longitude), min(latitude), min(longitude), max(latitude), max(longitude)\
from business\
where city = "Las Vegas" and (stars between 2 and 3) \
union \
select city, trim("stars 4-5") as Stars, avg(latitude), avg(longitude), min(latitude), min(longitude), max(latitude), max(longitude)\
from business\
where city = "Las Vegas" and (stars between 4 and 5) \
		\
\
+-----------+-----------+---------------+----------------+---------------+----------------+---------------+----------------+\
| city      | Stars     | avg(latitude) | avg(longitude) | min(latitude) | min(longitude) | max(latitude) | max(longitude) |\
+-----------+-----------+---------------+----------------+---------------+----------------+---------------+----------------+\
| Las Vegas | stars 2-3 | 36.1347367246 | -115.192377171 |       35.9953 |       -115.351 |       36.3027 |       -115.024 |\
| Las Vegas | stars 4-5 | 36.1255201671 | -115.204371122 |       35.6157 |       -115.509 |       36.3656 |       -114.742 |\
+-----------+-----------+---------------+----------------+---------------+----------------+---------------+----------------+\
\
		\
2. Group business based on the ones that are open and the ones that are closed. What differences can you find between the ones that are still open and the ones that are closed? List at least two differences and the SQL code you used to arrive at your answer.\
		\
i. Difference 1: From the group of 2-3 stars it is possible to infer that 21% of businesses are currently closed and that 79% of businesses are currently open. From the group of 4-5 stars it is possible to infer that only 11% of the businesses are currently closed while 89% of the businesses are currently open \
         \
         \
ii. Difference 2: From the group of 2-3 stars it is possible to infer that the businesses that are currently open received around 3.8 times more reviews than the places that are not open. From the group of 4-5 stars it is possible to infer that the businesses that are currently open received around 10 times more reviews than the places that are not open. \
         \
         \
         \
SQL code used for analysis:\
\
select city, trim("stars 2-3") as Stars,  trim("Not open") as open, count(is_open) as NumerBusiness, sum(review_count) as ReviewCount\
from business\
where city = "Las Vegas" and (stars between 2 and 3) and is_open = 0\
union\
select city, trim("stars 2-3") as Stars,  trim("open") as open, count(is_open) as NumerBusiness, sum(review_count) as ReviewCount\
from business\
where city = "Las Vegas" and (stars between 2 and 3) and is_open = 1\
union\
select city, trim("stars 4-5") as Stars,  trim("Not open") as open, count(is_open) as NumerBusiness, sum(review_count) as ReviewCount \
from business\
where city = "Las Vegas" and (stars between 4 and 5) and is_open = 0\
union\
select city, trim("stars 4-5") as Stars,  trim("open") as open, count(is_open) as NumerBusiness, sum(review_count) as ReviewCount \
from business\
where city = "Las Vegas" and (stars between 4 and 5) and is_open = 1\
\
+-----------+-----------+----------+---------------+-------------+\
| city      | Stars     | open     | NumerBusiness | ReviewCount |\
+-----------+-----------+----------+---------------+-------------+\
| Las Vegas | stars 2-3 | Not open |            85 |        3167 |\
| Las Vegas | stars 2-3 | open     |           318 |       12098 |\
| Las Vegas | stars 4-5 | Not open |            98 |        4141 |\
| Las Vegas | stars 4-5 | open     |           740 |       42811 |\
+-----------+-----------+----------+---------------+-------------+\
	\
3. For this last part of your analysis, you are going to choose the type of analysis you want to conduct on the Yelp dataset and are going to prepare the data for analysis.\
\
Ideas for analysis include: Parsing out keywords and business attributes for sentiment analysis, clustering businesses to find commonalities or anomalies between them, predicting the overall star rating for a business, predicting the number of fans a user will have, and so on. These are just a few examples to get you started, so feel free to be creative and come up with your own problem you want to solve. Provide answers, in-line, to all of the following:\
	\
i. Indicate the type of analysis you chose to do: \
\
A descriptive analysis will be carried out to evaluate if variables such as the age of the user, the number of reviews, if the user is cool, funny or usefull; determine the number of fans a new user will have \
         \
         \
ii. Write 1-2 brief paragraphs on the type of data you will need for your analysis and why you chose that data:\
                           \
Thanks to the analysis carried out, it is possible to infer that the age of the user does not influence the number of fans he has. This lowers the barrier to entry and makes it possible for new users to attract more fans.\
It is also possible to observe that the number of reviews does not influence the number of fans either. For example, user Gerald only has 2 reviews and is top number 1 in fans. While John, which has 102 reviews, only has 5 fans.\
It is evident that variables such as "useful", "cool" or even "compliment_photos" can generate an increase in fans. \
        \
iii. Output of your finished dataset:\
         \
         \
+-----------+------+---------+--------+-------------+------------+-----------+----------------+--------------------+-----------------+-------------------+-------------------+\
| name      | fans | AgeUser | counts | sum(useful) | sum(funny) | sum(cool) | compliment_hot | compliment_profile | compliment_cute | compliment_writer | compliment_photos |\
+-----------+------+---------+--------+-------------+------------+-----------+----------------+--------------------+-----------------+-------------------+-------------------+\
| Gerald    |  253 |       9 |      2 |       17530 |       2326 |     15008 |            206 |                 19 |               1 |               430 |               220 |\
| Lissa     |  120 |      14 |      2 |         455 |        150 |       342 |            417 |                 57 |              17 |               346 |                24 |\
| bernice   |  105 |      14 |      1 |         120 |        112 |       109 |            175 |                 18 |              26 |                49 |                47 |\
| Roanna    |  104 |      15 |      1 |        2995 |       1188 |       636 |            235 |                  7 |              13 |                92 |                46 |\
| .Hon      |  101 |      15 |      1 |        7850 |       5851 |      5104 |            226 |                 20 |              48 |                99 |                42 |\
| Nieves    |   80 |       8 |      1 |        1091 |        774 |       940 |            159 |                  3 |              13 |                77 |                79 |\
| Sui       |   78 |      12 |      1 |           9 |         18 |         2 |             41 |                  5 |               6 |                32 |                25 |\
| Koizumi   |   73 |      15 |      1 |         257 |        315 |       218 |            147 |                  8 |              13 |                53 |                32 |\
| rebecca   |   69 |      13 |      1 |           0 |          0 |         0 |              0 |                  0 |               0 |                 0 |                 0 |\
| Princeton |   64 |      12 |      1 |        1594 |        945 |      1114 |            400 |                 21 |              20 |               177 |               200 |\
| Alison    |   61 |      14 |      6 |         340 |        309 |       249 |            231 |                 12 |              21 |               114 |                23 |\
| Jayd      |   60 |      12 |      1 |          51 |         19 |        36 |             50 |                  3 |              10 |                24 |                 5 |\
| Quisha    |   58 |      12 |      1 |         689 |        300 |       575 |             38 |                  1 |               4 |                24 |                24 |\
| Renee     |   54 |      14 |     13 |        2713 |        694 |       348 |             40 |                  1 |               8 |                17 |                26 |\
| Dottsy    |   49 |      13 |      1 |        2654 |        989 |      2989 |            410 |                  3 |              15 |                62 |                18 |\
| Joc       |   49 |      16 |      1 |         472 |        654 |       606 |             81 |                  4 |              22 |                36 |                 7 |\
| Noushky   |   48 |       9 |      1 |         620 |        364 |       328 |            110 |                  3 |               5 |                32 |                51 |\
| Echo      |   46 |       8 |      1 |          16 |          1 |         1 |              0 |                  0 |               0 |                 0 |                 0 |\
| Anton     |   44 |      12 |      1 |        2181 |       1972 |      2046 |            351 |                 41 |              23 |               146 |                28 |\
| Susanna   |   44 |      13 |      2 |         139 |         84 |        74 |             16 |                  6 |               5 |                31 |                 8 |\
| Starr     |   42 |      11 |      1 |         183 |         98 |       216 |             51 |                  2 |               1 |                25 |                 8 |\
| Hanna     |   40 |      14 |      3 |           0 |          1 |         2 |             35 |                  1 |               6 |                21 |                12 |\
| kathleen  |   38 |      14 |      1 |          18 |         31 |         4 |             30 |                  1 |               2 |                12 |                 2 |\
| Dominic   |   37 |      10 |      6 |          81 |         31 |        52 |             16 |                  1 |               0 |                17 |                 1 |\
| Addy      |   36 |      10 |      1 |          91 |         11 |        15 |             14 |                  2 |               2 |                14 |                 5 |\
+-----------+------+---------+--------+-------------+------------+-----------+----------------+--------------------+-----------------+-------------------+-------------------+\
\
iv. Provide the SQL code you used to create your final dataset:\
\
select name, fans, strftime("%Y", Date("now")) - strftime("%Y", yelping_since) as AgeUser, count(review_count) as counts,\
sum(useful), sum(funny), sum(cool),\
compliment_hot, compliment_profile, compliment_cute, compliment_writer, compliment_photos\
from user\
group by name\
order by fans desc\
\
}